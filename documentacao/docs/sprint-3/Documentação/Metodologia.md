---
sidebar_position: 1
custom_edit_url: null
title: "Metodologia"
---

# Introdu√ß√£o

Aqui ser√° apresentada a metodologia do que foi feito durante a terceira Sprint de desenvolvimento da solu√ß√£o com o sistema do Turtlebot, nesta documenta√ß√£o ser√£o abordados os temas relacionados ao sistema `LiDAR` e seguran√ßa, al√©m do sistema de aquisi√ß√£o de imagens do rob√¥ em tempo real.

:::tip Lembre-se
O `LiDAR` no TurtleBot 3 √© um sensor de varredura a laser que mede dist√¢ncias at√© objetos em seu entorno. Ele emite pulsos de laser e calcula o tempo que cada pulso leva para refletir de volta ao sensor, permitindo a cria√ß√£o de um mapa 2D preciso do ambiente.
:::

Segue abaixo as etapas executadas para a realiza√ß√£o da terceira Sprint.

## Tecnologias

Durante est√° sprint, ser√£o utilizadas as seguintes tecnologias;

### üöÄ LiDAR
O LiDAR (Light Detection and Ranging) √© um sensor que mede dist√¢ncias at√© objetos em seu entorno. Ele funciona emitindo pulsos de laser e calculando o tempo que cada pulso leva para refletir de volta ao sensor, permitindo a cria√ß√£o de um mapa 2D preciso do ambiente.

**Principais Fun√ß√µes do LiDAR no TurtleBot 3:**

- **Navega√ß√£o Aut√¥noma:** Ajuda o TurtleBot 3 a navegar de forma aut√¥noma, evitando obst√°culos e planejando rotas seguras.
- **Detec√ß√£o de Obst√°culos:** Detecta obst√°culos ao redor do rob√¥, permitindo rea√ß√µes a mudan√ßas no ambiente e evitando colis√µes.

:::info 
O `LiDAR` pode ser utilizado de outras maneiras tamb√©m. Todavia at√© ent√£o usaremos o mesmo em nossa solu√ß√£o apenas para as fun√ß√µes descritas acima. Se quiser informa√ß√µes adicionais do que o LiDAR √© capaz de realizar, recomendo ler este [artigo](https://www.faro.com/en/Resource-Library/Article/What-is-Lidar#:~:text=Lidar%20technology%20is%20an%20ideal,models%20and%20map%20digital%20elevation.).
:::

### üì∏ OpenCV
OpenCV (Open Source Computer Vision Library) √© uma biblioteca de vis√£o computacional de c√≥digo aberto que fornece uma ampla gama de ferramentas para processamento de imagem e v√≠deo.

**Principais Fun√ß√µes do OpenCV:**

- **Processamento de Imagem:** Filtragem, transforma√ß√£o, segmenta√ß√£o e an√°lise das imagens adquiridas pelo rob√¥.
- **Detec√ß√£o de Objetos:** Algoritmos para reconhecimento e rastreamento de objetos, no caso do projeto ser√° utilizada a detec√ß√£o de entupimento nos canos.
- **Machine Learning:** Integra√ß√£o com modelos de aprendizado de m√°quina para tarefas de vis√£o computacional.

### üé• C√¢mera do Dobot Magician
A c√¢mera do Dobot Magician √© usada para captura de imagens e v√≠deos, permitindo a intera√ß√£o visual com o ambiente.

**Principais Fun√ß√µes da C√¢mera do Dobot Magician:**

- **Captura de Imagem:** Obten√ß√£o de imagens est√°ticas do ambiente para an√°lise.
- **V√≠deo em Tempo Real:** Transmiss√£o de v√≠deo ao vivo para monitoramento e controle.
- **Integra√ß√£o com Vis√£o Computacional:** Utilizada junto com bibliotecas como OpenCV para detec√ß√£o e reconhecimento de objetos.

### üéÆ Pygame
Pygame √© uma biblioteca de c√≥digo aberto para desenvolvimento de interfaces gr√°ficas e jogos em Python, proporcionando funcionalidades para cria√ß√£o de gr√°ficos, sons e intera√ß√µes de usu√°rio em tempo real.

**Principais Fun√ß√µes do Pygame:**

- **Desenvolvimento de Interfaces Gr√°ficas:** Ferramentas completas para cria√ß√£o de interfaces 2D interativas.
- **Gr√°ficos:** Suporte para renderiza√ß√£o de gr√°ficos em v√°rias resolu√ß√µes e formatos.
- **√Åudio:** Manipula√ß√£o e reprodu√ß√£o de sons e m√∫sicas em diferentes formatos.
- **Interatividade:** Permite a captura e manipula√ß√£o de eventos de entrada do usu√°rio, como teclado, mouse e joystick.

:::info Nota
Como ainda na Sprint 3, o projeto n√£o foi conclu√≠do, as tecnologias ainda podem ser mudadas posteriormente.
:::

### T√≥picos Utilizados Durante a Sprint 3

Seguindo o mesmo conceito de t√≥picos citados durante a [metodologia na Sprint 2](../../sprint-2/Documenta√ß√£o/Metodologia.md#t√≥picos), apresentamos o principal t√≥pico utilizado nesta Sprint para capacitar o rob√¥ com a tecnologia `LiDAR`.

#### T√≥pico Principal

**/scan**: O t√≥pico `scan` desempenha um papel crucial no funcionamento do rob√¥ equipado com `LiDAR`. Atrav√©s deste t√≥pico, o `LiDAR` envia os dados para o sistema ROS (Robot Operating System). Esses dados s√£o indispens√°veis para o controle da movimenta√ß√£o do rob√¥, permitindo que ele pare automaticamente ao detectar obst√°culos.

:::info Nota
üìù Para mais detalhes sobre a configura√ß√£o do `LiDAR` e como o t√≥pico `/scan` √© implementado no ROS, consulte a [documenta√ß√£o t√©cnica](../../sprint-2/Documenta√ß√£o/Metodologia.md#t√≥picos-e-n√≥s).
:::

---

## Cria√ß√£o dos Novos Sistemas

A seguir, discutiremos como os novos sistemas de [`LiDAR`](#üöÄ-lidar) e [processamento de imagens](#üì∏-opencv) foram integrados ao projeto, juntamente com as principais partes do c√≥digo relacionadas a esses sistemas.

:::info Nota
Este √© um resumo das modifica√ß√µes realizadas. Para acessar o c√≥digo fonte completo, visite o [GitHub do projeto](https://github.com/Inteli-College/2024-1B-T08-EC06-G04).
:::

### Adi√ß√£o do LiDAR no C√≥digo de Movimenta√ß√£o do Rob√¥

Para integrar o `LiDAR` ao c√≥digo do rob√¥, foram necess√°rias v√°rias modifica√ß√µes importantes. Entre elas, destacam-se:

- **Escuta do T√≥pico `scan`**: O rob√¥ foi configurado para escutar o t√≥pico `scan` a fim de receber dados de dist√¢ncia fornecidos pelo `LiDAR`.
- **Implementa√ß√£o de Ferramenta de Obstru√ß√£o**: Foi desenvolvida uma ferramenta que impede a movimenta√ß√£o do rob√¥ caso a frente esteja obstru√≠da, evitando que ele avance. De forma similar, se a parte traseira estiver obstru√≠da, o rob√¥ n√£o poder√° se mover para tr√°s.


### Bibliotecas referentes ao LiDAR utilizadas

Aqui est√£o as novas bibliotecas que foram integradas ao projeto nesta sprint relacionadas ao LiDAR:

#### LaserScan (sensor_msgs.msg)
A biblioteca `LaserScan` √© utilizada para processar os dados adquiridos atrav√©s da escuta do t√≥pico `scan`. Esta biblioteca √© essencial para interpretar as leituras do `LiDAR` e garantir que os dados de dist√¢ncia sejam corretamente compreendidos pelo sistema.

#### qos_profile_sensor_data (rclpy.qos)
A biblioteca `qos_profile_sensor_data` foi usada para adicionar Quality of Service (QOS) ao t√≥pico do ROS2. Isso garante a qualidade na transmiss√£o dos dados sensoriais, permitindo que o rob√¥ reaja rapidamente √†s mudan√ßas no ambiente.

:::info Nota
Todas as bibliotecas apresentadas na [**Sprint 2**](../../sprint-2/Documenta√ß√£o/Metodologia.md#bibliotecas-usadas) continuam sendo utilizadas nesta sprint.
:::

Segue abaixo o import exato das bibliotecas em python:

```python
from rclpy.qos import qos_profile_sensor_data
from sensor_msgs.msg import LaserScan
```

:::tip
Nenhuma destas bibliotecas √© necess√°rio utilizar o pip para baixar. Ambas **ja fazem parte** do ambiente de execu√ß√£o do ROS2
:::

### C√≥digo atualizado referente a movimenta√ß√£o do rob√¥

Abaixo est√° o c√≥digo atualizado de movimenta√ß√£o do rob√¥ com a integra√ß√£o do LiDAR. As novas funcionalidades introduzidas ser√£o discutidas detalhadamente a seguir, juntamente com a l√≥gica por tr√°s de sua implementa√ß√£o.

:::info Nota
Se seu rob√¥ n√£o √© capaz de interagir com o LiDAR, √© poss√≠vel seguir utilizando o c√≥digo desenvolvido na [Sprint 2](https://github.com/Inteli-College/2024-1B-T08-EC06-G04/tree/0.2.0) do rob√¥, por√©m **limitado** nas fun√ß√µes apresentadas naquela Sprint.
:::

Segue abaixo os trechos de c√≥digo relacionados ao funcionamento do `LiDAR`.

:::note
Este trecho de c√≥digo faz parte da funcionalidade do `LiDAR`. O c√≥digo completo possui outras funcionalidades al√©m das apresentadas aqui.
:::

```python
class RobotController(Node):
    def __init__(self):
        self.subscriber = self.create_subscription(
            LaserScan,
            'scan',
            self.lidar_callback,
            qos_profile=qos_profile_sensor_data
        )
        self.safety_distance = 0.35  # Reduziu a dist√¢ncia de parada pela metade


    def lidar_callback(self, msg):
        num_ranges = len(msg.ranges)
        sector_size = num_ranges // 12  # Ajustado para tornar o cone mais estreito
        # Definir √≠ndices dos setores usando a l√≥gica de divis√£o
        front_left_indices = range(num_ranges - sector_size, num_ranges)  # Parte frontal esquerda
        front_right_indices = range(0, sector_size)  # Parte frontal direita
        back_indices = range(5 * sector_size, 7 * sector_size)  # Parte traseira
        front_ranges = []
        back_ranges = []
        # Coletar dist√¢ncias da parte frontal esquerda
        for index in front_left_indices:
            if 0.01 < msg.ranges[index] < 100.0:  # Garantir que a dist√¢ncia esteja dentro dos limites v√°lidos
                front_ranges.append(msg.ranges[index])
        # Coletar dist√¢ncias da parte frontal direita
        for index in front_right_indices:
            if 0.01 < msg.ranges[index] < 100.0:  # Garantir que a dist√¢ncia esteja dentro dos limites v√°lidos
                front_ranges.append(msg.ranges[index])
        # Coletar dist√¢ncias da parte traseira
        for index in back_indices:
            if 0.01 < msg.ranges[index] < 100.0:  # Garantir que a dist√¢ncia esteja dentro dos limites v√°lidos
                back_ranges.append(msg.ranges[index])
        # Verificar se alguma das dist√¢ncias nas partes frontal ou traseira est√° abaixo do limite de seguran√ßa
        if any(r < self.safety_distance for r in front_ranges):
            self.front_clear = False
        else:
            self.front_clear = True
        if any(r < self.safety_distance for r in back_ranges):
            self.back_clear = False
        else:
            self.back_clear = True
        if not self.front_clear and self.linear_speed > 0:
            self.stop_robot()
            print(f"Obst√°culo detectado pr√≥ximo ao rob√¥, parando. Obst√°culo mais pr√≥ximo a {min(r for r in front_ranges if r < self.safety_distance)} metros.")
        elif not self.back_clear and self.linear_speed < 0:
            self.stop_robot()
            print(f"Obst√°culo detectado pr√≥ximo ao rob√¥ ao reverter, parando. Obst√°culo mais pr√≥ximo a {min(r for r in back_ranges if r < self.safety_distance)} metros.")
```

Segue abaixo as principais fun√ß√µes do c√≥digo mais bem explicadas e resumidas, para melhor entendimento

#### Inicializa√ß√£o do `RobotController`

Nesta parte do c√≥digo, estamos definindo a classe `RobotController` que herda da classe `Node`. O m√©todo `__init__` √© o construtor da classe e √© respons√°vel por inicializar o n√≥, criar uma assinatura para o t√≥pico `scan` do `LiDAR`, definir o callback `lidar_callback` e configurar o perfil de QoS para os dados do sensor. Tamb√©m definimos a dist√¢ncia de seguran√ßa (`safety_distance`) como 0.35 u.m (unidades de medida).

```python
class RobotController(Node):
    def __init__(self):
        self.subscriber = self.create_subscription(
            LaserScan,
            'scan',
            self.lidar_callback,
            qos_profile=qos_profile_sensor_data
        )
        self.safety_distance = 0.35
```

#### Callback do `LiDAR`

O m√©todo `lidar_callback` √© chamado sempre que uma nova mensagem `LaserScan` √© recebida no t√≥pico `scan`. Aqui, calculamos o n√∫mero total de leituras (`num_ranges`) e determinamos o tamanho de cada setor (`sector_size`) para dividir as leituras do `LiDAR` em diferentes partes do rob√¥ (frontal esquerda, frontal direita e traseira).

```python
# Coletar dist√¢ncias da parte frontal esquerda
for index in front_left_indices:
    if 0.01 < msg.ranges[index] < 100.0:  # Garantir que a dist√¢ncia esteja dentro dos limites v√°lidos
        front_ranges.append(msg.ranges[index])
# Coletar dist√¢ncias da parte frontal direita
for index in front_right_indices:
    if 0.01 < msg.ranges[index] < 100.0:  # Garantir que a dist√¢ncia esteja dentro dos limites v√°lidos
        front_ranges.append(msg.ranges[index])
# Coletar dist√¢ncias da parte traseira
for index in back_indices:
    if 0.01 < msg.ranges[index] < 100.0:  # Garantir que a dist√¢ncia esteja dentro dos limites v√°lidos
        back_ranges.append(msg.ranges[index])
```

#### Coletar dist√¢ncias

Para cada setor (frontal esquerda, frontal direita e traseira), coletamos as dist√¢ncias das leituras do `LiDAR` que est√£o dentro dos limites v√°lidos (0.01 a 100.0 metros). Essas dist√¢ncias s√£o armazenadas nas listas `front_ranges` e `back_ranges`.

```python
# Verificar se alguma das dist√¢ncias nas partes frontal ou traseira est√° abaixo do limite de seguran√ßa
if any(r < self.safety_distance for r in front_ranges):
    self.front_clear = False
else:
    self.front_clear = True
if any(r < self.safety_distance for r in back_ranges):
    self.back_clear = False
else:
    self.back_clear = True
```

#### Verifica√ß√£o de seguran√ßa

Nesta parte, verificamos se alguma das dist√¢ncias coletadas est√° abaixo do limite de seguran√ßa (`safety_distance`). Se estiver, definimos as vari√°veis `front_clear` e `back_clear` como `False`, indicando que h√° um obst√°culo na frente ou na traseira do rob√¥.

```python
if not self.front_clear and self.linear_speed > 0:
    self.stop_robot()
    print(f"Obst√°culo detectado pr√≥ximo ao rob√¥, parando. Obst√°culo mais pr√≥ximo a {min(r for r in front_ranges if r < self.safety_distance)} metros.")
elif not self.back_clear and self.linear_speed < 0:
    self.stop_robot()
    print(f"Obst√°culo detectado pr√≥ximo ao rob√¥ ao reverter, parando. Obst√°culo mais pr√≥ximo a {min(r for r in back_ranges if r < self.safety_distance)} metros.")
```

#### A√ß√£o de parada

Finalmente, se um obst√°culo for detectado e o rob√¥ estiver se movendo na dire√ß√£o do obst√°culo (para frente ou para tr√°s), o rob√¥ ser√° parado chamando o m√©todo `stop_robot()`. Uma mensagem √© impressa no console informando a presen√ßa do obst√°culo e a dist√¢ncia do obst√°culo mais pr√≥ximo.

### Adi√ß√£o do Pygame e Processamento de Imagens

Para proporcionar uma melhor visualiza√ß√£o do rob√¥, al√©m de um sistema de controle mais otimizado e com uma UX aprimorada, desenvolvemos uma interface de usu√°rio mais intuitiva e direta. Esta nova interface inclui:

- **Visualiza√ß√£o em Tempo Real**: Uma c√¢mera acoplada ao rob√¥ permite gravar e transmitir em tempo real o que o rob√¥ est√° fazendo, oferecendo uma vis√£o completa das opera√ß√µes.
- **Bot√µes de Controle Intuitivos**: Foram adicionados bot√µes de controle mais intuitivos e f√°ceis de usar, facilitando a intera√ß√£o e o controle do rob√¥.

A interface foi desenvolvida utilizando o Pygame, que oferece uma plataforma eficiente para criar aplica√ß√µes gr√°ficas interativas com Python.

### Bibliotecas Referentes ao Pygame

Abaixo est√£o listadas as bibliotecas utilizadas para o funcionamento do Pygame e para o processamento de imagens em tempo real:

- **cv2**: Utilizada para o processamento de imagens em tempo real.
- **base64**: Utilizada para codifica√ß√£o e decodifica√ß√£o de imagens.
- **numpy (np)**: Utilizada para opera√ß√µes matem√°ticas e manipula√ß√£o de arrays.
- **pygame**: Utilizada para criar a interface gr√°fica interativa.
- **PIL (Image)**: Utilizada para manipula√ß√£o de imagens.
- **io**: Utilizada para opera√ß√µes de entrada e sa√≠da.

#### C√≥digo de Importa√ß√£o

Segue abaixo o c√≥digo de importa√ß√£o dessas bibliotecas em Python:

```python
import cv2
import base64
import numpy as np
import pygame
from PIL import Image
import io
```

:::info Nota
Exceto pelas bibliotecas `base64` e `io`, todas as outras bibliotecas mencionadas precisam ser instaladas utilizando o gerenciador de pacotes do Python, `pip`. As instru√ß√µes detalhadas para a instala√ß√£o est√£o dispon√≠veis no guia de execu√ß√£o.
:::

### C√≥digo referente a interface visual e processamento de imagens

O c√≥digo abaixo √© referente ao processamento das imagens adquiridas pela c√¢mera do rob√¥. Afim de deixar mais claro como o mesmo foi executado e como pode ser alterado afim de abranger todas as necessidades.

:::warning
Qualquer altera√ß√£o no c√≥digo pode causar falhas ou mal-funcionamento do rob√¥, altere o mesmo em seu pr√≥prio risco.
:::

O c√≥digo abaixo √© utilizado dentro do rob√¥, onde o mesmo serve para passar as informa√ß√µes da webcam para o ambiente do ROS2 que contem o c√≥digo do Streamlit na m√°quina pessoal.

```python

# Importa√ß√µes das bibliotecas
import rclpy
from rclpy.node import Node
from std_msgs.msg import String
import cv2
import base64

# Classe principal
class Talker(Node):
    def __init__(self):
        super().__init__('talker')
        self.publisher_ = self.create_publisher(String, 'chatter', 10)
        self.cap = cv2.VideoCapture(0)
        if not self.cap.isOpened():
            self.get_logger().error("Erro: N√£o foi poss√≠vel acessar a webcam.")
            return
        self.cap.set(cv2.CAP_PROP_FPS, 30)  # Configura a c√¢mera para 60 FPS, se suportado
        timer_period = 0.0167  # aproximadamente 0.0167 segundos (60 FPS)
        self.timer = self.create_timer(timer_period, self.timer_callback)

    # M√©todo de callback
    def timer_callback(self):
        ret, frame = self.cap.read()
        if ret:
            _, buffer = cv2.imencode('.jpg', frame)
            jpg_as_text = base64.b64encode(buffer).decode('utf-8')
            msg = String()
            msg.data = jpg_as_text
            self.publisher_.publish(msg)
            self.get_logger().info('Publishing image as base64 string')
        else:
            self.get_logger().error('Could not read image from webcam')

    # M√©todo para finalizar a execu√ß√£o da classe
    def destroy_node(self):
        self.cap.release()
        super().destroy_node()

# Fun√ß√£o principal
def main(args=None):
    rclpy.init(args=args)
    node = Talker()
    rclpy.spin(node)
    node.destroy_node()
    rclpy.shutdown()

if __name__ == '__main__':
    main()
```

:::info Nota
Abaixo ser√° explicado melhor o c√≥digo, suas classes e m√©todos mais detalhadamente.
:::

#### Importa√ß√£o das bibliotecas

No espec√≠fico c√≥digo acima, a importa√ß√£o para todas as bibliotecas utilizadas √© o seguinte:

```python
import rclpy
from rclpy.node import Node
from std_msgs.msg import String
import cv2
import base64
```
As bibliotecas referentes a `rclpy` ja s√£o nativas do ambiente de execu√ß√£o do ROS2, ou seja, n√£o precisam ser baixadas com o pip.

#### Classe principal

Segue abaixo a classe principal de execu√ß√£o, os atributos e m√©todos da mesma.

```python
# Classe principal
class Talker(Node):
    def __init__(self):
        super().__init__('talker')
        self.publisher_ = self.create_publisher(String, 'chatter', 10)
        self.cap = cv2.VideoCapture(0)
        if not self.cap.isOpened():
            self.get_logger().error("Erro: N√£o foi poss√≠vel acessar a webcam.")
            return
        self.cap.set(cv2.CAP_PROP_FPS, 30)  # Configura a c√¢mera para 60 FPS, se suportado
        timer_period = 0.0167  # aproximadamente 0.0167 segundos (60 FPS)
        self.timer = self.create_timer(timer_period, self.timer_callback)

    # M√©todo de callback
    def timer_callback(self):
        ret, frame = self.cap.read()
        if ret:
            _, buffer = cv2.imencode('.jpg', frame)
            jpg_as_text = base64.b64encode(buffer).decode('utf-8')
            msg = String()
            msg.data = jpg_as_text
            self.publisher_.publish(msg)
            self.get_logger().info('Publicando imagem')
        else:
            self.get_logger().error('N√£o foi poss√≠vel ler imagem da webcam')

    # M√©todo para finalizar a execu√ß√£o da classe
    def destroy_node(self):
        self.cap.release()
        super().destroy_node()
``` 

A classe `Talker` herda de `Node`, a classe base para todos os n√≥s ROS2 em Python. Ela possui os seguintes atributos e m√©todos:

##### Atributos

- `publisher_`: Publicador ROS que envia mensagens do tipo `String` no t√≥pico `chatter`.
- `cap`: Objeto da classe `cv2.VideoCapture` para captura de v√≠deo da webcam.
- `timer`: Timer para chamar o m√©todo `timer_callback` periodicamente.

##### M√©todos

###### `__init__(self)`

- Inicializa a classe, configurando o publicador e a captura de v√≠deo.
- Configura a taxa de frames por segundo (FPS) da c√¢mera.
- Cria um timer para chamar `timer_callback` a cada 0.033 segundos (30 FPS).

###### `timer_callback(self)`

- Captura uma imagem da webcam.
- Codifica a imagem em base64 e publica como uma mensagem `String`.
- Registra uma mensagem de log indicando que a imagem foi publicada.

###### `destroy_node(self)`

- Libera a captura de v√≠deo e destr√≥i o n√≥ ROS.

#### Fun√ß√£o principal

A fun√ß√£o `main()` inicializa o n√≥ ROS, instancia a classe `Talker` e mant√©m o n√≥ em execu√ß√£o at√© ser interrompido.

```python
# Fun√ß√£o principal
def main(args=None):
    rclpy.init(args=args)
    node = Talker()
    rclpy.spin(node)
    node.destroy_node()
    rclpy.shutdown()
```

### C√≥digo referente ao recebimento das imagens adquiridas pelo rob√¥ e exibi√ß√£o na interface

O c√≥digo abaixo deve ser executado na m√°quina atribu√≠da ao rob√¥. O mesmo ir√° ser respons√°vel por exibir a interface visual ao operador, junto com os controles para opera√ß√£o do rob√¥. A parte abaixo representa apenas o trecho onde √© processada a imagem. Pois o c√≥digo completo chega a ocupar mais de 300 linhas.

:::warning
Lembrando, deve-se estar conectado na mesma rede __Wi-Fi__ que o rob√¥, caso contr√°rio n√£o ir√° funcionar.
:::

```python
class Listener(Node):
    def __init__(self):
        super().__init__('listener')
        self.subscription = self.create_subscription(
            String,
            'chatter',
            self.listener_callback,
            10)
        self.subscription

    # Callback do ouvinte para processar mensagens recebidas
    def listener_callback(self, msg):
        timestamp, jpg_as_text = msg.data.split('|', 1)
        timestamp = float(timestamp)
        current_time = time.time()
        latency = current_time - timestamp

        jpg_original = base64.b64decode(jpg_as_text)
        jpg_as_np = np.frombuffer(jpg_original, dtype=np.uint8)
        img = cv2.imdecode(jpg_as_np, cv2.IMREAD_COLOR)
        
        if img is not None:
            img_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)
            pil_image = Image.fromarray(img_rgb)
            img_bytes = io.BytesIO()
            pil_image.save(img_bytes, format="JPEG")
            img_bytes.seek(0)
            if not ui_queue.full():
                ui_queue.put((img_bytes, latency))
        else:
            self.get_logger().error('N√£o foi poss√≠vel decodificar a imagem')
```

:::info
Afim de analisar o c√≥digo completo, o mesmo est√° dispon√≠vel no seguinte local: `2024-1B-T08-EC06-G04/src/visor_v2/main.py` o mesmo possui coment√°rios e est√° facilmente leg√≠vel.
:::

#### Classe principal

A classe `Listener` herda de `Node`, a classe base para todos os n√≥s ROS2 em Python. Ela possui os seguintes atributos e m√©todos:

```python
class Listener(Node):
    def __init__(self):
        super().__init__('listener')
        self.subscription = self.create_subscription(
            String,
            'chatter',
            self.listener_callback,
            10)
        self.subscription

    # Callback do ouvinte para processar mensagens recebidas
    def listener_callback(self, msg):
        timestamp, jpg_as_text = msg.data.split('|', 1)
        timestamp = float(timestamp)
        current_time = time.time()
        latency = current_time - timestamp

        jpg_original = base64.b64decode(jpg_as_text)
        jpg_as_np = np.frombuffer(jpg_original, dtype=np.uint8)
        img = cv2.imdecode(jpg_as_np, cv2.IMREAD_COLOR)
        
        if img is not None:
            img_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)
            pil_image = Image.fromarray(img_rgb)
            img_bytes = io.BytesIO()
            pil_image.save(img_bytes, format="JPEG")
            img_bytes.seek(0)
            if not ui_queue.full():
                ui_queue.put((img_bytes, latency))
        else:
            self.get_logger().error('N√£o foi poss√≠vel decodificar a imagem')
```

#### Atributos

- `subscription`: Inscri√ß√£o no t√≥pico `chatter` para receber mensagens do tipo `String`.

:::info
Atributos s√£o vari√°veis que pertencem a um objeto ou classe em programa√ß√£o orientada a objetos. Eles armazenam dados ou informa√ß√µes que s√£o relevantes para o objeto ou classe. No contexto da classe `Listener`, os atributos s√£o usados para manter refer√™ncias a elementos importantes, como o publicador ROS e o espa√ßo reservado para as imagens no Streamlit.
:::

#### M√©todos

##### `__init__(self)`

- Inicializa a classe, configurando a inscri√ß√£o no t√≥pico e a interface Streamlit.
- Define o t√≠tulo da p√°gina Streamlit e cria um espa√ßo vazio para as imagens.

:::info
M√©todos s√£o fun√ß√µes definidas dentro de uma classe que descrevem os comportamentos ou a√ß√µes que um objeto dessa classe pode realizar. Eles podem manipular os atributos do objeto e realizar opera√ß√µes espec√≠ficas. Na classe `Listener`, os m√©todos incluem o construtor `__init__`, que inicializa os atributos da classe, e `listener_callback`, que processa as mensagens recebidas e exibe as imagens no Streamlit.
:::

##### `listener_callback(self, msg)`

- Decodifica a imagem base64 recebida.
- Converte a imagem para o formato RGB.
- Exibe a imagem na interface Streamlit.

#### Explica√ß√µes Adicionais

Segue abaixo algumas explica√ß√µes extras a respeito do c√≥digo, afim de n√£o deixar quaisquer d√∫vidas.

##### Decodifica√ß√£o da Imagem

- `jpg_original = base64.b64decode(msg.data)`: Decodifica a string base64 em bytes.
- `jpg_as_np = np.frombuffer(jpg_original, dtype=np.uint8)`: Converte os bytes em um array numpy.
- `img = cv2.imdecode(jpg_as_np, cv2.IMREAD_COLOR)`: Decodifica o array numpy em uma imagem OpenCV.

##### Convers√£o e Exibi√ß√£o

- `img_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)`: Converte a imagem de BGR para RGB.
- `pil_image = Image.fromarray(img_rgb)`: Converte a imagem para o formato PIL.
- `self.frame_holder.image(img_bytes, caption="Webcam Stream", use_column_width=True)`: Exibe a imagem na interface Streamlit.

:::warning
Lembre-se de encerrar corretamente o n√≥ ROS2 para evitar problemas de recursos.
:::

## Erros de execu√ß√£o

Afim de prevenir o prosseguimento do c√≥digo com algum erro ou algo do tipo, todos os c√≥digos realizados possuem um tratamento de erros para que o c√≥digo seja interrompido, ou pule a etapa se observar algum erro, como pode ser visto a seguir:

No c√≥digo do processamento e aquisi√ß√£o de imagens

```python
# Trecho do c√≥digo para tratamento de erros
        else:
            self.get_logger().error('N√£o foi poss√≠vel ler imagem da webcam')
```

No c√≥digo da interface visual e processamento de imagens

```python
# Trecho do c√≥digo para tratamento de erros
        else:
            self.get_logger().error('N√£o foi poss√≠vel decodificar a imagem')
```

J√° no c√≥digo referente ao LiDAR, se ele ler algum valor abaixo de 0,35 u.m, o robo ir√° parar no exato momento, se movimentando apenas para outras dire√ß√µes sem ser a que estava indo anteriormente para prevenir a batida.

```python
        # Verificar se alguma das dist√¢ncias nas partes frontal ou traseira est√° abaixo do limite de seguran√ßa
        if any(r < self.safety_distance for r in front_ranges):
            self.front_clear = False
        else:
            self.front_clear = True
        if any(r < self.safety_distance for r in back_ranges):
            self.back_clear = False
        else:
            self.back_clear = True
```

:::info
Para informa√ß√µes de execu√ß√£o, acesse a documenta√ß√£o a respeito das mesmas.
:::

## Seguran√ßa e confiabilidade

Na Sprint anterior, foi desenvolvida uma `Kill Switch` que interrompia a transmiss√£o de dados da m√°quina local para a `Raspberry Pi` do rob√¥. Nesta Sprint, avan√ßamos com uma nova `Kill Switch` capaz de encerrar a execu√ß√£o do c√≥digo de escuta do rob√¥ na `Raspberry Pi`, prevenindo erros e interfer√™ncias.

:::note
O pacote `Turtlebot3` deve estar instalado na `Raspberry Pi` para o funcionamento correto do c√≥digo, al√©m do ROS2.
:::

O c√≥digo implementado adiciona um novo servi√ßo de escuta que, ao receber uma chamada de emerg√™ncia, encerra o processo de bringup, interrompendo qualquer comunica√ß√£o via t√≥pico ROS com o rob√¥.

Para melhor visualiza√ß√£o, segue o mesmo abaixo.

```python
import rclpy
from rclpy.node import Node
from std_srvs.srv import Empty
import subprocess
import signal
import os

class TurtlebotBringupManager(Node):
    def __init__(self):
        super().__init__('turtlebot_bringup_manager')
        # Cria um servi√ßo que responde a chamadas de 'emergency_stop' com a fun√ß√£o de callback 'emergency_stop_callback'
        self.srv = self.create_service(Empty, 'emergency_stop', self.emergency_stop_callback)
        self.bringup_process = None

    def start_bringup(self):
        # Inicia o processo de bringup do TurtleBot3, lan√ßando o arquivo de lan√ßamento ROS2
        self.bringup_process = subprocess.Popen(['ros2', 'launch', 'turtlebot3_bringup', 'robot.launch.py'])

    def emergency_stop_callback(self, request, response):
        # Fun√ß√£o de callback chamada quando o servi√ßo de 'emergency_stop' √© ativado
        self.get_logger().info('Emergency stop received. Stopping TurtleBot3 bringup.')
        if self.bringup_process:
            # Encerra o processo de bringup do TurtleBot3 enviando um sinal de t√©rmino ao grupo de processos
            os.killpg(os.getpgid(self.bringup_process.pid), signal.SIGTERM)
            self.bringup_process = None
        return response

def main(args=None):
    # Inicializa o cliente ROS
    rclpy.init(args=args)
    manager = TurtlebotBringupManager()
    # Inicia o bringup do TurtleBot3
    manager.start_bringup()
    # Mant√©m o n√≥ em execu√ß√£o at√© que seja interrompido
    rclpy.spin(manager)
    # Destr√≥i o n√≥ e encerra a inicializa√ß√£o ROS
    manager.destroy_node()
    rclpy.shutdown()

if __name__ == '__main__':
    main()
```

1. **Imports**: 
   Importa as bibliotecas necess√°rias, incluindo `rclpy` para intera√ß√µes ROS2, `subprocess` para iniciar processos externos, `signal` para manipula√ß√£o de sinais e `os` para intera√ß√µes com o sistema operacional.

2. **TurtlebotBringupManager Class**:
   Define uma classe que herda de `Node`, representando um n√≥ ROS2.
   
   - **`__init__` Method**: 
     Inicializa o n√≥ e cria um servi√ßo ROS chamado `emergency_stop`, que chama a fun√ß√£o `emergency_stop_callback` quando ativado.
   
   - **`start_bringup` Method**: 
     Inicia o processo de bringup do TurtleBot3, lan√ßando um arquivo ROS2.
   
   - **`emergency_stop_callback` Method**: 
     Callback acionada pelo servi√ßo `emergency_stop` para interromper o processo de bringup, garantindo a interrup√ß√£o segura.

3. **main Function**:
   Fun√ß√£o principal que inicializa o n√≥ ROS2, inicia o bringup do TurtleBot3, mant√©m o n√≥ em execu√ß√£o e lida com a destrui√ß√£o do n√≥ e encerramento do ROS2 quando o programa √© interrompido.


:::warning
Lembrando novamente, para inicializar o projeto realizado at√© a Sprint 3, siga as instru√ß√µes dispon√≠veis [**aqui**](../Documenta√ß√£o/Instru√ß√µes%20de%20Execu√ß√£o.md)
:::